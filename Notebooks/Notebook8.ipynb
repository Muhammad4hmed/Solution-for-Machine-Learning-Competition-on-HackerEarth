{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install autofeat","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install sweetviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install GML","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install optuna","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\n\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, PolynomialFeatures\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVR\nfrom sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.cluster import KMeans\nfrom sklearn.ensemble import ExtraTreesRegressor, VotingRegressor, HistGradientBoostingRegressor\nfrom sklearn.linear_model import BayesianRidge, LinearRegression, LassoLars, Ridge, ElasticNet\n\n# import sweetviz as sv\n\n# import smogn\n\nimport matplotlib.pyplot as plt\n\nimport seaborn as sns\n\nfrom xgboost import XGBRegressor\n\nfrom catboost import CatBoostRegressor\n\nfrom lightgbm import LGBMRegressor\n\nimport tqdm\n\nfrom category_encoders import TargetEncoder\n\n# import optuna\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n# from autofeat import AutoFeatRegressor\n\n# from pystacknet.pystacknet import StackNetRegressor\n\nfrom GML.Ghalat_Machine_Learning import Ghalat_Machine_Learning","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def accuracy(y_true,y_pred):\n  return 100 * max(0,1-np.sqrt(mean_squared_error(y_true,y_pred)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/he-mlcomp/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(path+'Train.csv')\ntest = pd.read_csv(path+'Test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"types = {\n    'type0':'M2',\n    'type1':'M2',\n    'type2':'L2',\n    'type4':'L2',\n    'type3':'L2'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['COMPType'] = train['Compensation_and_Benefits'].map(types)\ntest['COMPType'] = test['Compensation_and_Benefits'].map(types)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_eid = test['Employee_ID'].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pvar = 'Hometown'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ntrain[pvar] = le.fit_transform(train[pvar])\ntest[pvar] = le.fit_transform(test[pvar])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Employee_ID'] = train['Employee_ID'].apply(lambda x: int(x.split('_')[1]))\ntest['Employee_ID'] = test['Employee_ID'].apply(lambda x: int(x.split('_')[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ncols = train.columns[train.dtypes == 'object']\nfor col in cols:\n    train[col].interpolate(method='linear',inplace=True)\n    test[col].interpolate(method='linear',inplace=True)\n\"\"\"\ntrain.fillna(-999,inplace=True)\ntest.fillna(-999,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.sort_values('Age',inplace=True)\ntrain.sort_values('Age',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_lgbm = {\n    'max_depth':16,\n    'learning_rate':0.002,\n    'n_estimators':1704,\n    'min_child_weight':17,\n    'eta':0.364\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g_var = 'Unit'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"minn = dict(train.groupby(g_var)['Attrition_rate'].min())\nmediann = dict(train.groupby(g_var)['Attrition_rate'].mean())\nmaxx = dict(train.groupby(g_var)['Attrition_rate'].max())\nstdd = dict(train.groupby(g_var)['Attrition_rate'].std())\n\ntrain['_Min'] = train[g_var].map(minn)\ntrain['_Avg'] = train[g_var].map(mediann)\ntrain['_Max'] = train[g_var].map(maxx)\ntrain['_Std'] = train[g_var].map(stdd)\ntest['_Min'] = test[g_var].map(minn)\ntest['_Avg'] = test[g_var].map(mediann)\ntest['_Max'] = test[g_var].map(maxx)\ntest['_Std'] = test[g_var].map(stdd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = train.columns[train.dtypes == 'object']\n\"\"\"\nenc = TargetEncoder()\ntrain[cols] = enc.fit_transform(train[cols],train['Attrition_rate'])\ntest[cols] = enc.transform(test[cols])\n\"\"\"\nfor col in cols:\n  dummies = pd.get_dummies(train[col])\n  train.drop([col],axis=1,inplace=True)\n  train = pd.concat([train,dummies],axis=1)\n  dummies = pd.get_dummies(test[col])\n  test.drop([col],axis=1,inplace=True)\n  test = pd.concat([test,dummies],axis=1)\n\n\"\"\"\nfor col in test.columns:\n    if train[col].isnull().any():\n        model = LGBMRegressor(**grid_lgbm)\n        t1 = train[~pd.isna(train[col])].copy()\n        t1.drop(['Attrition_rate'],axis=1,inplace=True)\n        t2 = train[pd.isna(train[col])].copy()\n        t2.drop(['Attrition_rate','Age'],axis=1,inplace=True)\n        t3 = test[pd.isna(test[col])].copy()\n        t3.drop(['Age'],axis=1,inplace=True)\n        model.fit(t1.drop([col],axis=1),t1[col])\n        train.loc[t2.index,col] = model.predict(t2)\n        test.loc[t3.index,col] = model.predict(t3)\n\"\"\"\n\"\"\"\nfor cols in test.columns:\n    train[cols].fillna(train[cols].mean(),inplace=True)\n    test[cols].fillna(test[cols].mean(),inplace=True)\n\"\"\"\npass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Can_Work_More_Years'] = 65 - train['Age'] - train['Time_of_service']\ntest['Can_Work_More_Years'] = 65 - test['Age'] - test['Time_of_service']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfuncs = [np.multiply, np.add, np.subtract, np.multiply, np.divide]\n\nfor i, func in enumerate(funcs):\n    train['Age_TOS'+str(i+1)] = func(train['Age'],train['Time_of_service'])\n    test['Age_TOS'+str(i+1)] = func(test['Age'],test['Time_of_service'])\n\n    train['AT_GR'+str(i+1)] = func(train['Age_TOS'+str(i+1)], train['growth_rate'])\n    test['AT_GR'+str(i+1)] = func(test['Age_TOS'+str(i+1)], test['growth_rate'])\n\n    train['TS_GR'+str(i+1)] = func(train['Time_of_service'], train['growth_rate'])\n    test['TS_GR'+str(i+1)] = func(test['Time_of_service'], test['growth_rate'])\n\n    train['PS_WLB'+str(i+1)] = func(train['Pay_Scale'], train['Work_Life_balance'])\n    test['PS_WLB'+str(i+1)] = func(test['Pay_Scale'], test['Work_Life_balance'])\n\n    train['Age_TSP'+str(i+1)] = func(train['Age'], train['Time_since_promotion'])\n    test['Age_TSP'+str(i+1)] = func(test['Age'],test['Time_since_promotion'])\n\n    train['Age_EMP'+str(i+1)] = func(train['Age'], train['Employee_ID'])\n    test['Age_EMP'+str(i+1)] = func(test['Age'], test['Employee_ID'])\n\n    train['TOS_EMP'+str(i+1)] = func(train['Time_of_service'],train['Employee_ID'])\n    test['TOS_EMP'+str(i+1)] = func(test['Time_of_service'],test['Employee_ID'])\n\n    train['ATOS_EMP'+str(i+1)] = func(train['Age_TOS'+str(i+1)], train['Employee_ID'])\n    test['ATOS_EMP'+str(i+1)] = func(test['Age_TOS'+str(i+1)], test['Employee_ID'])\n    break\n\"\"\"\nvar_names = ['VAR'+str(i) for i in range(1,8)]\nsums_tr = [] \nsubs_tr = [] \nmul_tr = [] \ndiv_tr = []\nsums_ts = []\nsubs_ts = []\nmul_ts = []\ndiv_ts = []\nfor row in train[var_names].itertuples():\n    sums_tr.append(row[1]+row[2]+row[3]+row[4]+row[5]+row[6]+row[7])\n    subs_tr.append(row[1]-row[2]-row[3]-row[4]-row[5]-row[6]-row[7])\n    mul_tr.append(row[1]*row[2]*row[3]*row[4]*row[5]*row[6]*row[7])\n    div_tr.append(row[1]/row[2]/row[3]/row[4]/row[5]/row[6]/row[7])\n    \nfor row2 in test[var_names].itertuples():\n    sums_ts.append(row[1]+row[2]+row[3]+row[4]+row[5]+row[6]+row[7])\n    subs_ts.append(row[1]-row[2]-row[3]-row[4]-row[5]-row[6]-row[7])\n    mul_ts.append(row[1]*row[2]*row[3]*row[4]*row[5]*row[6]*row[7])\n    div_ts.append(row[1]/row[2]/row[3]/row[4]/row[5]/row[6]/row[7])\n\ntrain['sum_VARS'] = sums_tr\ntrain['mul_VARS'] = mul_tr\ntrain['div_VARS'] = div_tr\ntest['sum_VARS'] = sums_ts\ntest['mul_VARS'] = mul_ts\ntest['div_VARS'] = div_ts\n\ntrain['mulvars_gr'] = train['growth_rate'] * train['mul_VARS']\ntest['mulvars_gr'] = test['growth_rate'] * test['mul_VARS']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_bayesian = {\n    'n_iter':10000,\n    'tol':6.42e-06,\n    'alpha_1':0.0001,\n    'alpha_2':6.58e-05,\n    'lambda_1':0.999,\n    'lambda_2':2.24e-05,\n    'compute_score':True,\n    'fit_intercept':True,\n    'normalize':False\n}\n\ngrid_ridge = {\n    'max_iter':90000,\n    'alpha': 0.23143352151759083, \n    'fit_intercept': True, \n    'normalize': False, \n    'tol': 0.0005243805101392493, \n    'solver': 'saga'\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.replace([np.inf, -np.inf], np.nan)\ntest = test.replace([np.inf, -np.inf], np.nan)\n\nfor col in test.columns:\n    train[col].replace([np.inf,-np.inf],np.nan,inplace=True)\n    test[col].replace([np.inf,-np.inf],np.nan,inplace=True)\n    train[col].interpolate(method='linear',inplace=True)\n    test[col].interpolate(method='linear',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['Attrition_rate'],axis=1)\ny = train['Attrition_rate'].copy().values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.replace([np.inf, -np.inf], np.nan)\ntest = test.replace([np.inf, -np.inf], np.nan)\nfor cols in X.columns:\n    X[cols].fillna(X[cols].mean(),inplace=True)\n    test[cols].fillna(X[cols].mean(),inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMRegressor(**grid_lgbm)\nlgbm.fit(X, y)\n\nfi = pd.DataFrame()\nfi['A'] = X.columns.values\nfi['B'] = lgbm.feature_importances_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi.sort_values('B',ascending = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fi.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols_to_d = fi[fi['B'] == 0].loc[:,'A']\nX.drop(cols_to_d,axis=1,inplace=True)\ntest.drop(cols_to_d,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndef perc(trial):\n    p1 = trial.suggest_uniform('p1',0.1,0.99)\n    p2 = trial.suggest_uniform('p2',0.1,0.99)\n    _scores = []\n    for v in tqdm.tqdm(np.unique(train[pvar])):\n        scores = []\n        X_ = X[X[pvar]==v].copy()\n        indexes = X[X[pvar]==v].index\n        y_ = y[indexes]\n\n        ridge = Ridge(**grid_ridge)\n        br = BayesianRidge()\n        for tr_in, val_in in KFold().split(X_, y_):\n            br.fit(X_.iloc[tr_in], y_[tr_in])\n            ridge.fit(X_.iloc[tr_in], y_[tr_in])\n            preds = (br.predict(X_.iloc[val_in]) * p1 + ridge.predict(X_.iloc[val_in]) * p2)\n            scores.append(accuracy(y_[val_in],preds))\n        _scores.append(np.mean(scores))\n    return -np.mean(_scores)\n\"\"\"\npass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# study = optuna.create_study()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# study.optimize(perc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1 = 0.9\np2 = 0.15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = pd.DataFrame()\nss['Emp_ID'] = test['Employee_ID'].copy()\nss['Employee_ID'] = test_eid\nss['Attrition_rate'] = np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n_scores = []\nfor v in tqdm.tqdm(np.unique(train[pvar])):\n    scores = []\n    X_ = X[X[pvar]==v].copy()\n    X_.drop(pvar,axis=1,inplace=True)\n    indexes = X[X[pvar]==v].index\n    y_ = y[indexes]\n    sgd = LinearRegression()\n    try:\n        for tr_in, val_in in KFold().split(X_, y_):\n            sgd.fit(X_.iloc[tr_in], y_[tr_in])\n            preds = (sgd.predict(X_.iloc[val_in])*1.05)\n            scores.append(accuracy(y_[val_in],preds))\n        _scores.append(np.mean(scores))\n    except:\n        pass\n    sgd.fit(X_,y_)\n            \n    test_ = test[test[pvar]==v].copy()\n    test_.drop(pvar,axis=1,inplace=True)\n    if test_.empty:\n        continue\n    e_ind = test[test[pvar]==v].loc[:,'Employee_ID']\n    preds = (sgd.predict(test_)*1.05)\n    ind = ss[ss['Emp_ID'].isin(e_ind)].index\n    ss.at[ind,'Attrition_rate'] = preds\n\"\"\"\npass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nscores = []\nfor tr_in, val_in in KFold(shuffle=False).split(X, y):\n    reg = StackingRegressor(estimators=estimators,final_estimator=BayesianRidge(**grid_bayesian))\n    reg.fit(X.iloc[tr_in], y[tr_in])\n    preds = reg.predict(X.iloc[val_in])\n    sco = accuracy(y[val_in],preds)\n    print(sco)\n    scores.append(sco)\n\"\"\"\npass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_scores = []\nfor v in tqdm.tqdm(np.unique(train[pvar])):\n    scores = []\n    X_ = X[X[pvar]==v].copy()\n    X_.drop(pvar,axis=1,inplace=True)\n    indexes = X[X[pvar]==v].index\n    y_ = y[indexes]\n    y_ = np.log1p(y_)\n    br = BayesianRidge()\n    ridge = Ridge(**grid_ridge)\n    try:\n        for tr_in, val_in in KFold().split(X_, y_):\n            br.fit(X_.iloc[tr_in], y_[tr_in])\n            ridge.fit(X_.iloc[tr_in], y_[tr_in])\n            preds = (br.predict(X_.iloc[val_in])*p1 + ridge.predict(X_.iloc[val_in])*p2)\n            preds = np.expm1(preds)\n            scores.append(accuracy(y_[val_in],preds))\n        _scores.append(np.mean(scores))\n    except:\n        pass\n    br.fit(X_,y_)\n    ridge.fit(X_,y_)\n    test_ = test[test[pvar]==v].copy()\n    if test_.empty:\n        continue\n    test_.drop(pvar,axis=1,inplace=True)\n    e_ind = test[test[pvar]==v].loc[:,'Employee_ID']\n    preds = br.predict(test_)*p1 + ridge.predict(test_)*p2\n    preds = np.expm1(preds)\n    ind = ss[ss['Emp_ID'].isin(e_ind)].index\n    ss.at[ind,'Attrition_rate'] = preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(_scores)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.drop(['Emp_ID'],axis=1,inplace=True)\nss.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Attrition_rate'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss['Attrition_rate'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}